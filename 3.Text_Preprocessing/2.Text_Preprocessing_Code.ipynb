{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a4cdf75-1321-4ee7-9b2e-df3114e7570f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a77af07c-bd7f-49be-af40-c1a08397f076",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"IMDB Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7cb3604-e0ee-44ca-890b-9bbc75706771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bb31ad-2cf9-4429-9643-5f83d3dd4f29",
   "metadata": {},
   "source": [
    "# 1.LowerCasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe4c5efc-141f-44bd-9e1b-461760f814a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"basically there's a family where a little boy (jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />this movie is slower than a soap opera... and suddenly, jake decides to become rambo and kill the zombie.<br /><br />ok, first of all when you're going to make a film you must decide if its a thriller or a drama! as a drama the movie is watchable. parents are divorcing & arguing like in real life. and then we have jake with his closet which totally ruins all the film! i expected to see a boogeyman similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. as for the shots with jake: just ignore them.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][3].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ae66e0c-af85-4041-ad26-e8a742664d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        one of the other reviewers has mentioned that ...\n",
       "1        a wonderful little production. <br /><br />the...\n",
       "2        i thought this was a wonderful way to spend ti...\n",
       "3        basically there's a family where a little boy ...\n",
       "4        petter mattei's \"love in the time of money\" is...\n",
       "                               ...                        \n",
       "49995    i thought this movie did a down right good job...\n",
       "49996    bad plot, bad dialogue, bad acting, idiotic di...\n",
       "49997    i am a catholic taught in parochial elementary...\n",
       "49998    i'm going to have to disagree with the previou...\n",
       "49999    no one expects the star trek movies to be high...\n",
       "Name: review, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7196db-8376-4c56-a09f-a46ca514bfb6",
   "metadata": {},
   "source": [
    "## 2.Removing HTMl tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a265ec8f-035e-4201-b605-f55227f1aad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_tags(text):\n",
    "    pattern=re.compile(\"<.*?>\")\n",
    "    return pattern.sub(r'',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06a3b9e5-88cc-4d74-849b-18cb88ed3ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a wonderful little production. the'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=\"a wonderful little production. <br /><br />the\"\n",
    "remove_tags(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "117a466e-806a-41de-a815-f9ff92584f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        One of the other reviewers has mentioned that ...\n",
       "1        A wonderful little production. The filming tec...\n",
       "2        I thought this was a wonderful way to spend ti...\n",
       "3        Basically there's a family where a little boy ...\n",
       "4        Petter Mattei's \"Love in the Time of Money\" is...\n",
       "                               ...                        \n",
       "49995    I thought this movie did a down right good job...\n",
       "49996    Bad plot, bad dialogue, bad acting, idiotic di...\n",
       "49997    I am a Catholic taught in parochial elementary...\n",
       "49998    I'm going to have to disagree with the previou...\n",
       "49999    No one expects the Star Trek movies to be high...\n",
       "Name: review, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"review\"].apply(remove_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1664ce06-dd27-4640-8c20-9fbc80a0027b",
   "metadata": {},
   "source": [
    "## 3.Remove URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "140c020d-c522-4bab-b35f-50abe3801f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(text):\n",
    "    pattern=re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return pattern.sub(r'',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca822edc-0dcd-4e90-a49d-efb8d97e9559",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1=\"this is first text https://www.kaggle.com/code/campusx/text-preprocessing/script\"\n",
    "text2= \"This is second text http://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\"\n",
    "text3=\"This is third text www.goggle.com\"\n",
    "text4=\"For notebook https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews check www.google.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40f88f29-a779-49e7-a18a-6b94c4833938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'For notebook https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews check www.google.com'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ade13cb-dcfb-4904-998f-ca1dbc253280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is first text '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_url(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c951dbbe-1550-4818-afb0-ec560881e2c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is second text '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_url(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d90e30f-7a41-47fd-9031-fd7a3f8b1e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is third text '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_url(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4d00b8f-b734-46f9-93bb-99c0f80aecac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'For notebook  check '"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_url(text4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b191770-55fb-4e10-9e05-2ea33338bb9b",
   "metadata": {},
   "source": [
    "## 4.Remove Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34df15b8-da5c-4a5b-a49a-31081af0e9b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string , time\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bdd34ee6-c2fc-4ac7-a1aa-65d814862af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude=string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9cedfb5d-3215-4b4c-a86d-527ad269e5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc(text):\n",
    "    for char in exclude:\n",
    "        text=text.replace(char,'')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3333b0b8-50b4-489a-9478-24c6c4153c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"this . is ? string & with punctuation*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "952312b9-72b4-4f92-9fce-38248f4df780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this  is  string  with punctuation'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_punc(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c876a224-0713-4f7a-a0cb-f4cf13791b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this  is  string  with punctuation\n",
      "49.82948303222656\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "print(remove_punc(text))\n",
    "time1=time.time()-start\n",
    "print(time1*50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca61a54-3c9a-414d-8da5-e74011170900",
   "metadata": {},
   "source": [
    "##### The above technique is not efficient and much slower on large amount of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5fce6f29-d4c6-4848-bff7-3620cd460aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc1(text):\n",
    "    return text.translate(str.maketrans('','',exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fbc49219-22c7-4679-a1ef-061b54691335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.96061325073242\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "remove_punc1(text)\n",
    "time2=time.time()-start\n",
    "print(time2*50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d49f5f-9741-4a7a-af65-a0da9a330e53",
   "metadata": {},
   "source": [
    "## 5.Chat_Word_Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90310000-f719-42f4-99ab-e6b4000d9924",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_words={\n",
    "    \"AFAIK\": \"As Far As I Know\",\n",
    "    \"AFK\": \"Away From Keyboard\",\n",
    "    \"ASAP\": \"As Soon As Possible\",\n",
    "    \"ATK\": \"At The Keyboard\",\n",
    "    \"ATM\": \"At The Moment\",\n",
    "    \"A3\": \"Anytime, Anywhere, Anyplace\",\n",
    "    \"BAK\": \"Back At Keyboard\",\n",
    "    \"BBL\": \"Be Back Later\",\n",
    "    \"BBS\": \"Be Back Soon\",\n",
    "    \"BFN\": \"Bye For Now\",\n",
    "    \"B4N\": \"Bye For Now\",\n",
    "    \"BRB\": \"Be Right Back\",\n",
    "    \"BRT\": \"Be Right There\",\n",
    "    \"BTW\": \"By The Way\",\n",
    "    \"B4\": \"Before\",\n",
    "    \"CU\": \"See You\",\n",
    "    \"CUL8R\": \"See You Later\",\n",
    "    \"CYA\": \"See You\",\n",
    "    \"FAQ\": \"Frequently Asked Questions\",\n",
    "    \"FC\": \"Fingers Crossed\",\n",
    "    \"FWIW\": \"For What It's Worth\",\n",
    "    \"FYI\": \"For Your Information\",\n",
    "    \"GAL\": \"Get A Life\",\n",
    "    \"GG\": \"Good Game\",\n",
    "    \"GN\": \"Good Night\",\n",
    "    \"GMTA\": \"Great Minds Think Alike\",\n",
    "    \"GR8\": \"Great!\",\n",
    "    \"G9\": \"Genius\",\n",
    "    \"IC\": \"I See\",\n",
    "    \"ICQ\": \"I Seek you (also a chat program)\",\n",
    "    \"ILU\": \"I Love You\",\n",
    "    \"IMHO\": \"In My Honest/Humble Opinion\",\n",
    "    \"IMO\": \"In My Opinion\",\n",
    "    \"IOW\": \"In Other Words\",\n",
    "    \"IRL\": \"In Real Life\",\n",
    "    \"KISS\": \"Keep It Simple, Stupid\",\n",
    "    \"LDR\": \"Long Distance Relationship\",\n",
    "    \"LMAO\": \"Laugh My A.. Off\",\n",
    "    \"LOL\": \"Laughing Out Loud\",\n",
    "    \"LTNS\": \"Long Time No See\",\n",
    "    \"L8R\": \"Later\",\n",
    "    \"MTE\": \"My Thoughts Exactly\",\n",
    "    \"M8\": \"Mate\",\n",
    "    \"NRN\": \"No Reply Necessary\",\n",
    "    \"OIC\": \"Oh I See\",\n",
    "    \"PITA\": \"Pain In The A..\",\n",
    "    \"PRT\": \"Party\",\n",
    "    \"PRW\": \"Parents Are Watching\",\n",
    "    \"QPSA\": \"Que Pasa?\",\n",
    "    \"ROFL\": \"Rolling On The Floor Laughing\",\n",
    "    \"ROFLOL\": \"Rolling On The Floor Laughing Out Loud\",\n",
    "    \"ROTFLMAO\": \"Rolling On The Floor Laughing My A.. Off\",\n",
    "    \"SK8\": \"Skate\",\n",
    "    \"STATS\": \"Your sex and age\",\n",
    "    \"ASL\": \"Age, Sex, Location\",\n",
    "    \"THX\": \"Thank You\",\n",
    "    \"TTFN\": \"Ta-Ta For Now!\",\n",
    "    \"TTYL\": \"Talk To You Later\",\n",
    "    \"U\": \"You\",\n",
    "    \"U2\": \"You Too\",\n",
    "    \"U4E\": \"Yours For Ever\",\n",
    "    \"WB\": \"Welcome Back\",\n",
    "    \"WTF\": \"What The F...\",\n",
    "    \"WTG\": \"Way To Go!\",\n",
    "    \"WUF\": \"Where Are You From?\",\n",
    "    \"W8\": \"Wait...\",\n",
    "    \"7K\": \"Sick:-D Laugher\",\n",
    "    \"TFW\": \"That feeling when\",\n",
    "    \"MFW\": \"My face when\",\n",
    "    \"MRW\": \"My reaction when\",\n",
    "    \"IFYP\": \"I feel your pain\",\n",
    "    \"TNTL\": \"Trying not to laugh\",\n",
    "    \"JK\": \"Just kidding\",\n",
    "    \"IDC\": \"I don’t care\",\n",
    "    \"ILY\": \"I love you\",\n",
    "    \"IMU\": \"I miss you\",\n",
    "    \"ADIH\": \"Another day in hell\",\n",
    "    \"ZZZ\": \"Sleeping, bored, tired\",\n",
    "    \"WYWH\": \"Wish you were here\",\n",
    "    \"TIME\": \"Tears in my eyes\",\n",
    "    \"BAE\": \"Before anyone else\",\n",
    "    \"FIMH\": \"Forever in my heart\",\n",
    "    \"BSAAW\": \"Big smile and a wink\",\n",
    "    \"BWL\": \"Bursting with laughter\",\n",
    "    \"BFF\": \"Best friends forever\",\n",
    "    \"CSL\": \"Can’t stop laughing\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9a44e74-3023-4ae1-8014-2da6e728da18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AFAIK': 'As Far As I Know',\n",
       " 'AFK': 'Away From Keyboard',\n",
       " 'ASAP': 'As Soon As Possible',\n",
       " 'ATK': 'At The Keyboard',\n",
       " 'ATM': 'At The Moment',\n",
       " 'A3': 'Anytime, Anywhere, Anyplace',\n",
       " 'BAK': 'Back At Keyboard',\n",
       " 'BBL': 'Be Back Later',\n",
       " 'BBS': 'Be Back Soon',\n",
       " 'BFN': 'Bye For Now',\n",
       " 'B4N': 'Bye For Now',\n",
       " 'BRB': 'Be Right Back',\n",
       " 'BRT': 'Be Right There',\n",
       " 'BTW': 'By The Way',\n",
       " 'B4': 'Before',\n",
       " 'CU': 'See You',\n",
       " 'CUL8R': 'See You Later',\n",
       " 'CYA': 'See You',\n",
       " 'FAQ': 'Frequently Asked Questions',\n",
       " 'FC': 'Fingers Crossed',\n",
       " 'FWIW': \"For What It's Worth\",\n",
       " 'FYI': 'For Your Information',\n",
       " 'GAL': 'Get A Life',\n",
       " 'GG': 'Good Game',\n",
       " 'GN': 'Good Night',\n",
       " 'GMTA': 'Great Minds Think Alike',\n",
       " 'GR8': 'Great!',\n",
       " 'G9': 'Genius',\n",
       " 'IC': 'I See',\n",
       " 'ICQ': 'I Seek you (also a chat program)',\n",
       " 'ILU': 'I Love You',\n",
       " 'IMHO': 'In My Honest/Humble Opinion',\n",
       " 'IMO': 'In My Opinion',\n",
       " 'IOW': 'In Other Words',\n",
       " 'IRL': 'In Real Life',\n",
       " 'KISS': 'Keep It Simple, Stupid',\n",
       " 'LDR': 'Long Distance Relationship',\n",
       " 'LMAO': 'Laugh My A.. Off',\n",
       " 'LOL': 'Laughing Out Loud',\n",
       " 'LTNS': 'Long Time No See',\n",
       " 'L8R': 'Later',\n",
       " 'MTE': 'My Thoughts Exactly',\n",
       " 'M8': 'Mate',\n",
       " 'NRN': 'No Reply Necessary',\n",
       " 'OIC': 'Oh I See',\n",
       " 'PITA': 'Pain In The A..',\n",
       " 'PRT': 'Party',\n",
       " 'PRW': 'Parents Are Watching',\n",
       " 'QPSA': 'Que Pasa?',\n",
       " 'ROFL': 'Rolling On The Floor Laughing',\n",
       " 'ROFLOL': 'Rolling On The Floor Laughing Out Loud',\n",
       " 'ROTFLMAO': 'Rolling On The Floor Laughing My A.. Off',\n",
       " 'SK8': 'Skate',\n",
       " 'STATS': 'Your sex and age',\n",
       " 'ASL': 'Age, Sex, Location',\n",
       " 'THX': 'Thank You',\n",
       " 'TTFN': 'Ta-Ta For Now!',\n",
       " 'TTYL': 'Talk To You Later',\n",
       " 'U': 'You',\n",
       " 'U2': 'You Too',\n",
       " 'U4E': 'Yours For Ever',\n",
       " 'WB': 'Welcome Back',\n",
       " 'WTF': 'What The F...',\n",
       " 'WTG': 'Way To Go!',\n",
       " 'WUF': 'Where Are You From?',\n",
       " 'W8': 'Wait...',\n",
       " '7K': 'Sick:-D Laugher',\n",
       " 'TFW': 'That feeling when',\n",
       " 'MFW': 'My face when',\n",
       " 'MRW': 'My reaction when',\n",
       " 'IFYP': 'I feel your pain',\n",
       " 'TNTL': 'Trying not to laugh',\n",
       " 'JK': 'Just kidding',\n",
       " 'IDC': 'I don’t care',\n",
       " 'ILY': 'I love you',\n",
       " 'IMU': 'I miss you',\n",
       " 'ADIH': 'Another day in hell',\n",
       " 'ZZZ': 'Sleeping, bored, tired',\n",
       " 'WYWH': 'Wish you were here',\n",
       " 'TIME': 'Tears in my eyes',\n",
       " 'BAE': 'Before anyone else',\n",
       " 'FIMH': 'Forever in my heart',\n",
       " 'BSAAW': 'Big smile and a wink',\n",
       " 'BWL': 'Bursting with laughter',\n",
       " 'BFF': 'Best friends forever',\n",
       " 'CSL': 'Can’t stop laughing'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f452a366-e7fb-4c0b-a114-fe5f11eb0998",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_conversation(text):\n",
    "    new_text=[]\n",
    "    for w in text.split():\n",
    "      if w.upper() in chat_words:\n",
    "        new_text.append(chat_words[w.upper()])\n",
    "      else:\n",
    "        new_text.append(w)\n",
    "    return \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a8ca7d0-e024-4908-9f52-b186ea9fcb91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Laugh My A.. Off he is the best'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_conversation(\"LMAO he is the best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0ff37a9b-c23d-4954-9998-28024b28f408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bursting with laughter with that joke'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_conversation(\"BWL with that joke\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6497cf03-423d-42ad-903b-54afe618a21f",
   "metadata": {},
   "source": [
    "## 6.Spelling_Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "513a0285-1874-445c-97f5-17ab22eca0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b7347a84-84a8-432e-8a85-4397c5fd1b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'His text is uncertain at some condition due to heisenbergesss uncertainty principal'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_text=\"This texxxt is uncertaaain at some conudition due to heisenbergesss uncertainityy principal\"\n",
    "text_blb=TextBlob(incorrect_text)\n",
    "text_blb.correct().string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2f6297-bf55-4732-a4a2-af3b5c6e5525",
   "metadata": {},
   "source": [
    "## 7.Stop_Words_Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4ade70d0-4fd7-4841-8695-0fb1d75a93fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b4568ccf-8e21-4690-9f55-505ae542532d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words(\"English\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "acdc175e-496d-4ce3-ba45-85a12f046e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_words(text):\n",
    "    new_txt=[] \n",
    "    for words in text.split():\n",
    "        if words in stopwords.words(\"English\"):\n",
    "            new_txt.append(' ')\n",
    "        else:\n",
    "            new_txt.append(words)\n",
    "    x=new_txt[:]\n",
    "    new_txt.clear()\n",
    "    return \" \".join(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f547599b-e466-4ba3-bd3a-d5194e188b0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hiiii       boy whose name   Aniket   apple   eaten    '"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_words(\"hiiii there is a boy whose name is Aniket the apple is eaten by him\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416d6f93-c515-4388-872d-3483f5ee8560",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"review\"].apply(remove_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc7617e-0b34-487f-9371-b72ab59c7a34",
   "metadata": {},
   "source": [
    "## 8.Handling_emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f13174bc-97c4-42fe-8de9-b0037e4a533f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a43839af-a091-4b0a-94c3-03f8f10753a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emoji(text):\n",
    "    emoji_pattern=re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\" #emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\" #symbols and pictograph\n",
    "                               u\"\\U0001F680-\\U0001F6FF\" #trasport and map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\" #flas (ios)\n",
    "                               u\"\\U00002702-\\U00002780\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                             \"]+\",flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'',text )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c06eed92-c2d8-4cf6-9a1e-7f97571a7f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HI there how are you '"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_emoji(\"HI there how are you 😎😎😎😎\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7d2df98a-eab1-413a-9f7c-c556a323527c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LMAO '"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_emoji(\"LMAO 😑🙄\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2284ad37-bb0d-4384-86b9-c5ca8732ede1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e16f0b55-7024-44ed-9aa5-558bd1eba4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bb1a4346-8812-4c29-bd72-17b0c23ec297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi there :smiling_face_with_sunglasses::smiling_face_with_sunglasses:\n"
     ]
    }
   ],
   "source": [
    "print(emoji.demojize(\"Hi there 😎😎\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "29030b8f-d8e0-447f-9c9b-70fc13a2552c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What a movie :smiling_face::smiling_face::beaming_face_with_smiling_eyes:\n"
     ]
    }
   ],
   "source": [
    "print(emoji.demojize(\"What a movie ☺☺😁\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c4bd55-0150-450f-bd47-e5e35ee24f4a",
   "metadata": {},
   "source": [
    "## 9.Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46b0a6e-f9aa-472c-8709-ffb1858ea9b8",
   "metadata": {},
   "source": [
    "#### A.Using te split function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fa6d5fa4-7b84-4052-b09f-e7aade092b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'an', 'Indian']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#word tokeization\n",
    "sent1=\"I am an Indian\"\n",
    "sent1.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a2cd296d-f6e7-4175-9b9c-3384476b15a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['My name is Rohan', ' Watching BOLN', ' On Disney Channel']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sentence Tokenization\n",
    "sent2=\"My name is Rohan. Watching BOLN. On Disney Channel\"\n",
    "sent2.split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c8410a1c-8334-4fbc-8f98-2733ba3efd19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'delhi!']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Problem with split Function\n",
    "sent3=\"I am going to delhi!\"\n",
    "sent3.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4597f0a6-bf7d-424b-8668-4b8572d4e2fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Where do you think, where should i go ? i  have 3 days holiday']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent4=\"Where do you think, where should i go ? i  have 3 days holiday\"\n",
    "sent4.split('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4679c901-a915-4e2e-9a9e-b63203dc5f84",
   "metadata": {},
   "source": [
    "#### B.Regular Expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "35927075-bcdd-4956-8caa-4a857ca5dedc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'delhi']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent5=\"I am going to Delhi!\"\n",
    "tokens=re.findall(\"[\\w]+\",sent3)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "02a9df98-03c4-4a05-b589-b2a666be1c63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nam efficitur, elit sed fermentum fermentum, sem turpis gravida libero, vel sagittis justo nisl id urna',\n",
       " ' Maecenas id est vitae ipsum bibendum feugiat',\n",
       " ' Cras scelerisque, lorem vel pellentesque gravida, dui magna dignissim nunc, in vehicula dolor orci sed nulla',\n",
       " ' Nulla facilisi',\n",
       " ' In hac habitasse platea dictumst',\n",
       " ' Aliquam erat volutpat']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=\"Nam efficitur, elit sed fermentum fermentum, sem turpis gravida libero, vel sagittis justo nisl id urna. Maecenas id est vitae ipsum bibendum feugiat? Cras scelerisque, lorem vel pellentesque gravida, dui magna dignissim nunc, in vehicula dolor orci sed nulla. Nulla facilisi. In hac habitasse platea dictumst. Aliquam erat volutpat\"\n",
    "sentence=re.compile('[.!?]').split(text)\n",
    "sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7779df-e81a-4100-af4f-240b6b5e2f63",
   "metadata": {},
   "source": [
    "#### C.NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2e14195e-64e8-41f3-a07b-9827361bc8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize,sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a2495d6a-dd22-4d85-bc62-63c56b45ae14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'going', 'to', 'visit', 'delhi', '!']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent1=\"I going to visit delhi!\"\n",
    "word_tokenize(sent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "42dc27bf-93d9-4d5b-adb5-effa4b2b30ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nam efficitur, elit sed fermentum fermentum, sem turpis gravida libero, vel sagittis justo nisl id urna.',\n",
       " 'Maecenas id est vitae ipsum bibendum feugiat?',\n",
       " 'Cras scelerisque, lorem vel pellentesque gravida, dui magna dignissim nunc, in vehicula dolor orci sed nulla.',\n",
       " 'Nulla facilisi.',\n",
       " 'In hac habitasse platea dictumst.',\n",
       " 'Aliquam erat volutpat:']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=\"Nam efficitur, elit sed fermentum fermentum, sem turpis gravida libero, vel sagittis justo nisl id urna. Maecenas id est vitae ipsum bibendum feugiat? Cras scelerisque, lorem vel pellentesque gravida, dui magna dignissim nunc, in vehicula dolor orci sed nulla. Nulla facilisi. In hac habitasse platea dictumst. Aliquam erat volutpat:\"\n",
    "sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2912e600-540c-4676-bf66-f9b4e97b45cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent5='I have a Ph.D in A.I'\n",
    "sent6=\"We're to help mail us at 1234@abn.com\"\n",
    "sent7=\"A 5km ride cost 12$\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8987cfda-0efc-473b-b667-9d5385c1cccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'have', 'a', 'Ph.D', 'in', 'A.I']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(sent5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1f52268a-b794-40d7-8abb-2f8d5160ae8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We', \"'re\", 'to', 'help', 'mail', 'us', 'at', '1234', '@', 'abn.com']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(sent6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b20cda1b-25fb-4b85-9cde-ba8aa9113290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', '5km', 'ride', 'cost', '12', '$']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(sent7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591d21c9-4f5a-43c8-b179-f75749157706",
   "metadata": {},
   "source": [
    "#### D.Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cc596e9c-f5eb-4e6a-99eb-3a5373b13c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp=spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f98fe60e-777d-4012-96d6-895024e99424",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1=nlp(sent1)\n",
    "doc2=nlp(sent5)\n",
    "doc3=nlp(sent6)\n",
    "doc4=nlp(sent7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9af0f7b7-42dc-477b-8c06-5b391120de03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "have\n",
      "a\n",
      "Ph\n",
      ".\n",
      "D\n",
      "in\n",
      "A.I\n"
     ]
    }
   ],
   "source": [
    "for token in doc2:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a36c6ea9-ec33-46a5-95de-666b8a94f043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "going\n",
      "to\n",
      "visit\n",
      "delhi\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "for token in doc1:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "88c3a81d-8920-4af1-ad74-aa2cee7503e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We\n",
      "'re\n",
      "to\n",
      "help\n",
      "mail\n",
      "us\n",
      "at\n",
      "1234@abn.com\n"
     ]
    }
   ],
   "source": [
    "for token in doc3:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a5333cf6-b0fa-4f2a-a64b-73a65ac0d021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "5\n",
      "km\n",
      "ride\n",
      "cost\n",
      "12\n",
      "$\n"
     ]
    }
   ],
   "source": [
    "for token in doc4:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fef3cb-cf73-4f1a-83ab-3d8f875d816b",
   "metadata": {},
   "source": [
    "## 10.Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "19ca7902-bfd1-400e-8eca-60649cee5dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "09cc8680-7fec-4fd4-ab2d-b47257323d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps=PorterStemmer()\n",
    "def stem_words(text):\n",
    "    return \" \".join([ps.stem(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "84315c5a-f55c-453f-baa6-1d1536d03a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'word word word word'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample=\"word words wording worded\"\n",
    "stem_words(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3fdc03a7-da37-43d6-a1ac-61d5c8345170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the children were play in the playground. they happili play game and ran around. each child enjoy the activities, laugh and shout with joy.'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=\"The children were playing in the playground. They happily played games and ran around. Each child enjoyed the activities, laughing and shouting with joy.\"\n",
    "stem_words(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf6cf8b-26e0-433b-9d83-f928e696faad",
   "metadata": {},
   "source": [
    "- Stemmming might be loose the original form and meaning of word sometimes\n",
    "- Lemmatization is used for solving problem in stemming\n",
    "- Stemming is Faster then lemmatization\n",
    "- Lemmatization is Slower as it checks words  in Dictionary\n",
    "- Lemmatization not looses the original meaning of words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487fb4ee-b168-4ee2-82e7-05928770c845",
   "metadata": {},
   "source": [
    "## 11.Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1420520c-5f97-4984-a8ba-55ef32489694",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\acer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\acer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\acer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\acer\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['He', 'be', 'run', 'and', 'eat', 'at', 'the', 'same', 'time', '.', 'He', 'have', 'a', 'bad', 'habit', 'of', 'swimming', 'after', 'play', 'in', 'the', 'long', 'sun', '.']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# Initialize the WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Function to convert NLTK POS tags to WordNet POS tags\n",
    "def get_wordnet_pos(nltk_pos_tag):\n",
    "    if nltk_pos_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_pos_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_pos_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_pos_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "# Input sentence\n",
    "sentence = \"He was running and eating at the same time. He has a bad habit of swimming after playing in the long sun.\"\n",
    "\n",
    "# Tokenize the sentence\n",
    "words = nltk.word_tokenize(sentence)\n",
    "\n",
    "# Get POS tags for the words\n",
    "pos_tags = nltk.pos_tag(words)\n",
    "\n",
    "# Lemmatize each word with its POS tag\n",
    "lemmatized_words = [lemmatizer.lemmatize(word, get_wordnet_pos(pos)) for word, pos in pos_tags]\n",
    "\n",
    "# Print the lemmatized words\n",
    "\n",
    "print(lemmatized_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31296662-5eb3-4b16-a0ce-8b9cab45f480",
   "metadata": {},
   "source": [
    "## Happy Learning....!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6460f0dd-a192-4e59-a337-24d7031783ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
